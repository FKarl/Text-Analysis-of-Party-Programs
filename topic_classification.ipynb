{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Topic classification using cosine similarity on the word embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "Same as in the data_exploration notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "# some general imports\n",
    "from enum import Enum\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "\n",
    "import re\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "class Party(Enum):\n",
    "    AFD = 0\n",
    "    CDU = 1\n",
    "    FDP = 2\n",
    "    GRUENE = 3\n",
    "    LINKE = 4\n",
    "    SPD = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "# https://spacy.io/models/de#de_core_news_md\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "\n",
    "# stopwords\n",
    "nltk_stopwords = stopwords.words('german')\n",
    "\n",
    "# build stopwords list\n",
    "all_stopwords = list(set(STOP_WORDS) | set(nltk_stopwords))\n",
    "with open('data_exploration/custom_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    all_stopwords += [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Load files\n",
    "party_text = {}\n",
    "for party in Party:\n",
    "    all_stopwords.extend(['{}'.format(party.name.lower())])\n",
    "    with open('resources/' + party.name + '.txt', encoding='utf-8', errors='ignore') as txt:\n",
    "        file = \" \".join(l for l in txt)\n",
    "        # remove gender *\n",
    "        file = re.sub(r'\\*innen(\\w*)\\s', r'\\1 ', file)\n",
    "    party_text[party] = file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    doc = nlp(\" \".join(texts))\n",
    "    texts_out = [token.lemma_ for token in doc if token.pos_ in allowed_postags and token.lemma_ not in all_stopwords]\n",
    "\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "def prepare_data(party: Party):\n",
    "    \"\"\"\n",
    "    Prepare data for topic classification.\n",
    "    Split into sections and lemmatize.\n",
    "\n",
    "    :param party: The party to get the text from\n",
    "    :return: a dict containing the text and the lemmatized text seperated in sections\n",
    "    \"\"\"\n",
    "    # get sections\n",
    "    sections = re.split(r'\\n\\s\\n', party_text[party])\n",
    "    cleaned_sections = {}\n",
    "    for section in sections:\n",
    "        wordbag = gensim.utils.simple_preprocess(section)\n",
    "        #lemmatize\n",
    "        # wordbag = lemmatization(wordbag)\n",
    "        cleaned_sections[section] = wordbag\n",
    "\n",
    "    # return all cleaned sections except empty ones\n",
    "    return dict(filter(lambda x: len(x[1]) > 0, cleaned_sections.items()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create target clusters\n",
    "based on lda from the [data_exploration notebook](data_exploration/topic_modeling_playground.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from transformers import BertTokenizer, TFBertModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "# based on lda from the data_exploration notebook\n",
    "cluster_dict = {\n",
    "    \"UMWELT\":\n",
    "        [\"umwelt\", \"klima\", \"klimaschutz\", \"ökologie\", \"co2\", \"co\", \"landwirtschaft\", \"klimakrise\", \"treibhaus\",\n",
    "         \"emissionen\", \"ausbau\", \"innovative\", \"natur\", \"wasser\", \"landwirtschaft\", \"nachhaltig\", \"strom\",\n",
    "         \"solar\", \"windkraft\", \"wasserkraft\", \"kohlekraft\", \"atomkraft\", \"kernenergie\", \"energiewende\",\n",
    "         \"erneuerbar\", \"öl\", \"gas\", \"energie\", \"nachhaltig\", \"wasserstoff\", \"luftqualität\", \"umwelt\", \"wälder\",\n",
    "         \"erneuerbare energie\"],\n",
    "\n",
    "    \"WIRTSCHAFT\":\n",
    "        [\"unternehmen\", \"selbstständige\", \"firma\", \"markt\", \"kapital\", \"finanzierung\", \"ezb\", \"banken\",\n",
    "         \"staatsanleihen\", \"währungsfonds\", \"staatsanleihen\", \"kredit\", \"euro\", \"industrie\", \"schulden\", \"steuern\",\n",
    "         \"konzern\", \"kapital\", \"finanzen\"],\n",
    "\n",
    "    \"BILDUNG\":\n",
    "        [\"student\", \"schüler\", \"schule\", \"gesamtschule\", \"lehrer\", \"universität\", \"lehre\", \"elternunabhängig\",\n",
    "         \"bildung\", \"hochschulen\", \"wissenschaft\", \"bildung\", \"erasmus\", \"forschung\", \"lehre\", \"ausbildung\",\n",
    "         \"weiterbildung\", \"aufstiegsmöglichkeit\", \"bildungsstandard\", \"innovationen\", \"bafög\", \"studium\"],\n",
    "\n",
    "    \"GESELLSCHAFT\":\n",
    "        [\"gesellschaft\", \"kultur\", \"freiheit\", \"privat\", \"kulturelle\", \"antisemitismus\",\n",
    "         \"vorbild\", \"frauen\", \"familie\", \"identität\", \"gender\", \"sprache\", \"leben\", \"religion\", \"christentum\", \"islam\",\n",
    "         \"diskriminierung\", \"menschenrechte\", \"kunst\", \"adoption\"],\n",
    "\n",
    "    \"INNEN\":\n",
    "        [\"schutz\", \"polizei\", \"schützen\", \"überwachung\", \"datenschutz\", \"sicherheit\", \"bundeswehr\", \"asyl\",\n",
    "         \"integration\", \"migrant\", \"flüchtling\", \"immigrant\", \"toleranz\", \"zuwanderung\", \"asylbewerber\",\n",
    "         \"krimminalität\", \"zuwanderung\", \"kontrolle\", \"bundespolizei\", \"gefahr\", \"terroristen\", \"gewalt\"],\n",
    "\n",
    "    \"ARBEIT_UND_SOZIALES\":\n",
    "        [\"rente\", \"harz4\", \"arbeitslosengeld\", \"pflege\", \"wohngeld\", \"familie\", \"arbeitslos\", \"sozial\", \"bauen\",\n",
    "         \"wohnungen\", \"sozialbau\", \"kinder\", \"pflegen\", \"arbeitssuchende\", \"grundsicherung\", \"eltern\", \"jugendlich\",\n",
    "         \"gesundheit\", \"arzt\", \"armut\", \"einkommen\", \"löhne\", \"tarifvertrag\", \"bürgergeld\",\n",
    "         \"sozialstaat\", \"teilhabe\", \"bezahlbar\"]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dbmdz/bert-base-german-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-german-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Model from https://huggingface.co/dbmdz/bert-base-german-uncased\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-german-uncased\", do_lower_case=True)\n",
    "model = TFBertModel.from_pretrained(\"dbmdz/bert-base-german-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "def convert_to_embeddings(cluster):\n",
    "    idx = tokenizer.encode(cluster)\n",
    "    idx = np.array(idx)[None, :]\n",
    "    embedding = model(idx)\n",
    "    tensor = np.array(embedding[0][0][1:-1])\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classify text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Party.AFD\n",
      "UMWELT : 12\n",
      "WIRTSCHAFT : 103\n",
      "BILDUNG : 2\n",
      "GESELLSCHAFT : 82\n",
      "INNEN : 210\n",
      "ARBEIT_UND_SOZIALES : 7\n",
      "\n",
      "Party.CDU\n",
      "UMWELT : 98\n",
      "WIRTSCHAFT : 400\n",
      "BILDUNG : 14\n",
      "GESELLSCHAFT : 156\n",
      "INNEN : 452\n",
      "ARBEIT_UND_SOZIALES : 7\n",
      "\n",
      "Party.FDP\n",
      "UMWELT : 41\n",
      "WIRTSCHAFT : 91\n",
      "BILDUNG : 13\n",
      "GESELLSCHAFT : 31\n",
      "INNEN : 190\n",
      "ARBEIT_UND_SOZIALES : 7\n",
      "\n",
      "Party.GRUENE\n",
      "UMWELT : 45\n",
      "WIRTSCHAFT : 108\n",
      "BILDUNG : 1\n",
      "GESELLSCHAFT : 15\n",
      "INNEN : 130\n",
      "ARBEIT_UND_SOZIALES : 8\n",
      "\n",
      "Party.LINKE\n",
      "UMWELT : 25\n",
      "WIRTSCHAFT : 171\n",
      "BILDUNG : 6\n",
      "GESELLSCHAFT : 44\n",
      "INNEN : 194\n",
      "ARBEIT_UND_SOZIALES : 27\n",
      "\n",
      "Party.SPD\n",
      "UMWELT : 21\n",
      "WIRTSCHAFT : 44\n",
      "BILDUNG : 1\n",
      "GESELLSCHAFT : 10\n",
      "INNEN : 47\n",
      "ARBEIT_UND_SOZIALES : 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    " results = {}\n",
    " for party in Party:\n",
    "    # create list of vectors\n",
    "    section_dict = prepare_data(party)\n",
    "    mean_vectors = [convert_to_embeddings(txt).mean(0) for txt in section_dict.values()]\n",
    "\n",
    "    feature_matrix = np.array(mean_vectors)\n",
    "\n",
    "    # vector space for dict (maybe mean(0) ?)\n",
    "    dic_vectors = {key: convert_to_embeddings(value) for key, value in cluster_dict.items()}\n",
    "\n",
    "    similarities = np.array(\n",
    "        [metrics.pairwise.cosine_similarity(feature_matrix, dic_y).T.tolist()[0] for dic_y in dic_vectors.values()]).T\n",
    "\n",
    "    labels = list(dic_vectors.keys())\n",
    "    for i in range(len(similarities)):\n",
    "\n",
    "        # if there is a similarity to a cluster -> random cluster\n",
    "        if sum(similarities[i]) == 0:\n",
    "            similarities[i] = [0] * len(labels)\n",
    "            similarities[i][np.random.choice(range(len(labels)))] = 1\n",
    "\n",
    "        # rescale to 1\n",
    "        similarities[i] = similarities[i] / sum(similarities[i])\n",
    "\n",
    "    #classify based on similarities\n",
    "    prediction = [(labels[np.argmax(pred)], max(pred)) for pred in similarities]\n",
    "\n",
    "    # print number of topics for each topic\n",
    "    print(party)\n",
    "    for topic in labels:\n",
    "        print(topic, \":\", len(list(filter(lambda x: x[0] == topic, prediction))))\n",
    "    print()\n",
    "\n",
    "    results[party] = (section_dict, prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}